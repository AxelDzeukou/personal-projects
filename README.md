# personal-projects
**Sentiment analysis and k-means clustering**

-Performed sentiment analysis on clustered web pages scraped on Concordia universityâ€™s website using spidy

**Spark and Dask assignments**

-Applied spark rdds and dataframes along with dask bags and dataframes for data analysis
-Implemented recommendations using alternating least squares in spark MLlib

**Descriptive data analysis on tips data**

-Implemented descriptive data analysis on tips data from waiters and created visualizations using pandas, scipy, and matplotlib

**Data wrangling**

-Performed data wrangling on ecological data including n-grams for text clustering, implementing numeric facets, and renaming columns

**Single-pass in-memory indexing search engine**

-Developed search engine on SPIMI indexer using nltk to create the terms, BeautifulSoup to collect areas of text from sgm files, and pandas for data transformation
